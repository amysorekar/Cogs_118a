{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anand Mysorekar\n",
    "\n",
    "## Cogs 118a Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This project evaluates the performance of three classification models—Random Forest, Support Vector Machine (SVM), and Logistic Regression—on three datasets from the UCI Machine Learning Repository. Each dataset is structured for binary classification, and the models are trained using hyperparameter tuning and evaluated under varying data partitions (20/80, 50/50, 80/20 splits). Metrics such as training, validation, and test accuracy are used to compare the models' effectiveness. Results show that Random Forest consistently achieves the highest accuracy across datasets, while SVM and Logistic Regression demonstrate varying strengths depending on the data's complexity and feature distribution. This study highlights the importance of selecting appropriate classifiers and hyperparameters for different datasets and provides insights into model behavior under different training-to-testing ratios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Classification is a fundamental task in machine learning, where the goal is to assign inputs to predefined categories. Binary classification, in particular, has widespread applications such as identifying spam emails, diagnosing medical conditions, and predicting customer churn. Selecting the appropriate classification model is critical for achieving high accuracy and robustness across different datasets.\n",
    "\n",
    "The performance of a classifier often depends on the dataset's characteristics, such as the number of features, the size of the training set, and the feature distributions. Comparing multiple classifiers on the same datasets provides insights into their strengths, weaknesses, and generalizability.\n",
    "\n",
    "This project aims to evaluate and compare the performance of three popular classification models on three classification datasets. By exploring their behavior under different training/testing splits and tuning hyperparameters, this study seeks to identify general trends and best practices in classifier selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: [Adult](http://archive.ics.uci.edu/dataset/2/adult)\n",
    "Predicting whether annual income of an individual exceeds $50K/yr based on census data. 48,842 instances, 14 features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and assign column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"age\",\n",
    "    \"class\",\n",
    "    \"fnlwgt\", # drop\n",
    "    \"education_level\",\n",
    "    \"education-num\", # drop\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gains\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"salary\"\n",
    "]\n",
    "\n",
    "\n",
    "adult_dataset = pd.read_csv('adult_dataset/adult.data', names=column_names) # read the dataset\n",
    "adult_dataset = adult_dataset.drop(columns=[\"fnlwgt\", \"education-num\"]) # drop these columns\n",
    "adult_dataset = adult_dataset[~adult_dataset.map(lambda x: str(x).strip()).isin(['?']).any(axis=1)] # remove rows with missing values\n",
    "\n",
    "print(adult_dataset.dtypes)\n",
    "adult_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the features are categorical, so we will need to encode them before training the models. Many of the features have lots of possible values, so we will group them into fewer categories to reduce the dimensionality of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group similar values for dimensionality reduction for effecient encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    'Private': 'Private',\n",
    "    'Self-emp-not-inc': 'Self-employed',\n",
    "    'Self-emp-inc': 'Self-employed',\n",
    "    'Federal-gov': 'Government',\n",
    "    'Local-gov': 'Government',\n",
    "    'State-gov': 'Government',\n",
    "    'Without-pay': 'Other',\n",
    "    'Never-worked': 'Other'\n",
    "}\n",
    "\n",
    "adult_dataset['class'] = adult_dataset['class'].str.strip()\n",
    "adult_dataset['class'] = adult_dataset['class'].map(class_mapping)\n",
    "print(adult_dataset['class'].unique())\n",
    "\n",
    "\n",
    "education_mapping = {\n",
    "    'Bachelors': 'Undergraduate',\n",
    "    'Some-college': 'Undergraduate',\n",
    "    'Assoc-acdm': 'Undergraduate',\n",
    "    'Assoc-voc': 'Undergraduate',\n",
    "    'Masters': 'Postgraduate',\n",
    "    'Doctorate': 'Postgraduate',\n",
    "    'Prof-school': 'Postgraduate',\n",
    "    'HS-grad': 'Lower Education',\n",
    "    '12th': 'Lower Education',\n",
    "    '11th': 'Lower Education',\n",
    "    '10th': 'Lower Education',\n",
    "    '9th': 'Lower Education',\n",
    "    '7th-8th': 'Lower Education',\n",
    "    '5th-6th': 'Lower Education',\n",
    "    '1st-4th': 'Lower Education',\n",
    "    'Preschool': 'Lower Education'\n",
    "}\n",
    "\n",
    "adult_dataset['education_level'] = adult_dataset['education_level'].str.strip()\n",
    "adult_dataset['education_level'] = adult_dataset['education_level'].map(education_mapping)\n",
    "print(adult_dataset['education_level'].unique())\n",
    "\n",
    "\n",
    "marital_mapping = {\n",
    "    'Never-married': 'Single',\n",
    "    'Married-civ-spouse': 'Married',\n",
    "    'Married-AF-spouse': 'Married',\n",
    "    'Divorced': 'Previously Married',\n",
    "    'Separated': 'Previously Married',\n",
    "    'Widowed': 'Previously Married',\n",
    "    'Married-spouse-absent': 'Married'\n",
    "}\n",
    "\n",
    "adult_dataset['marital_status'] = adult_dataset['marital_status'].str.strip()\n",
    "adult_dataset['marital_status'] = adult_dataset['marital_status'].map(marital_mapping)\n",
    "print(adult_dataset['marital_status'].unique())\n",
    "\n",
    "\n",
    "occupation_mapping = {\n",
    "    'Tech-support': 'White-collar',\n",
    "    'Craft-repair': 'Blue-collar',\n",
    "    'Other-service': 'Service',\n",
    "    'Sales': 'White-collar',\n",
    "    'Exec-managerial': 'White-collar',\n",
    "    'Prof-specialty': 'White-collar',\n",
    "    'Handlers-cleaners': 'Blue-collar',\n",
    "    'Machine-op-inspct': 'Blue-collar',\n",
    "    'Adm-clerical': 'White-collar',\n",
    "    'Farming-fishing': 'Blue-collar',\n",
    "    'Transport-moving': 'Blue-collar',\n",
    "    'Priv-house-serv': 'Service',\n",
    "    'Protective-serv': 'Service',\n",
    "    'Armed-Forces': 'Military'\n",
    "}\n",
    "\n",
    "adult_dataset['occupation'] = adult_dataset['occupation'].str.strip()\n",
    "adult_dataset['occupation'] = adult_dataset['occupation'].map(occupation_mapping)\n",
    "print(adult_dataset['occupation'].unique())\n",
    "\n",
    "\n",
    "relationship_mapping = {\n",
    "    'Wife': 'Spouse',\n",
    "    'Husband': 'Spouse',\n",
    "    'Own-child': 'Dependent',\n",
    "    'Not-in-family': 'Unrelated',\n",
    "    'Other-relative': 'Dependent',\n",
    "    'Unmarried': 'Unrelated'\n",
    "}\n",
    "\n",
    "adult_dataset['relationship'] = adult_dataset['relationship'].str.strip()\n",
    "adult_dataset['relationship'] = adult_dataset['relationship'].map(relationship_mapping)\n",
    "print(adult_dataset['relationship'].unique())\n",
    "\n",
    "\n",
    "race_mapping = {\n",
    "    'White': 'White',\n",
    "    'Black': 'Black',\n",
    "    'Asian-Pac-Islander': 'Asian',\n",
    "    'Amer-Indian-Eskimo': 'Indigenous',\n",
    "    'Other': 'Other'\n",
    "}\n",
    "\n",
    "adult_dataset['race'] = adult_dataset['race'].str.strip()\n",
    "adult_dataset['race'] = adult_dataset['race'].map(race_mapping)\n",
    "print(adult_dataset['race'].unique())\n",
    "\n",
    "\n",
    "sex_mapping = {\n",
    "    'Male': 1,\n",
    "    'Female': 0\n",
    "}\n",
    "\n",
    "adult_dataset['sex'] = adult_dataset['sex'].str.strip()\n",
    "adult_dataset['sex'] = adult_dataset['sex'].map(sex_mapping)\n",
    "print(adult_dataset['sex'].unique())\n",
    "\n",
    "\n",
    "country_mapping = {\n",
    "    'United-States': 'North America',\n",
    "    'Canada': 'North America',\n",
    "    'Outlying-US(Guam-USVI-etc)': 'North America',\n",
    "    'Puerto-Rico': 'North America',\n",
    "    'Mexico': 'Latin America',\n",
    "    'Cuba': 'Latin America',\n",
    "    'Dominican-Republic': 'Latin America',\n",
    "    'Jamaica': 'Latin America',\n",
    "    'Haiti': 'Latin America',\n",
    "    'Trinadad&Tobago': 'Latin America',\n",
    "    'El-Salvador': 'Latin America',\n",
    "    'Guatemala': 'Latin America',\n",
    "    'Honduras': 'Latin America',\n",
    "    'Nicaragua': 'Latin America',\n",
    "    'Ecuador': 'Latin America',\n",
    "    'Peru': 'Latin America',\n",
    "    'Columbia': 'Latin America',\n",
    "    'England': 'Europe',\n",
    "    'Germany': 'Europe',\n",
    "    'Italy': 'Europe',\n",
    "    'Poland': 'Europe',\n",
    "    'Portugal': 'Europe',\n",
    "    'Ireland': 'Europe',\n",
    "    'France': 'Europe',\n",
    "    'Greece': 'Europe',\n",
    "    'Scotland': 'Europe',\n",
    "    'Yugoslavia': 'Europe',\n",
    "    'Hungary': 'Europe',\n",
    "    'Holand-Netherlands': 'Europe',\n",
    "    'Cambodia': 'Asia',\n",
    "    'India': 'Asia',\n",
    "    'Japan': 'Asia',\n",
    "    'China': 'Asia',\n",
    "    'Philippines': 'Asia',\n",
    "    'Vietnam': 'Asia',\n",
    "    'Laos': 'Asia',\n",
    "    'Thailand': 'Asia',\n",
    "    'Hong': 'Asia',\n",
    "    'Taiwan': 'Asia',\n",
    "    'Iran': 'Middle East',\n",
    "    'South': 'Other',\n",
    "    'Israel': 'Middle East',  \n",
    "    'Other': 'Other'\n",
    "}\n",
    "\n",
    "adult_dataset['native_country'] = adult_dataset['native_country'].str.strip()\n",
    "adult_dataset['native_country'] = adult_dataset['native_country'].map(country_mapping)\n",
    "print(adult_dataset['native_country'].unique())\n",
    "\n",
    "\n",
    "salary_mapping = {\n",
    "    '>50K': 1,\n",
    "    '<=50K': 0\n",
    "}\n",
    "\n",
    "adult_dataset['salary'] = adult_dataset['salary'].str.strip()\n",
    "adult_dataset['salary'] = adult_dataset['salary'].map(salary_mapping)\n",
    "print(adult_dataset['salary'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks much better and much more manageable. Now we can encode the data. Most of the features are nominal, meaning they don't have an inherent order, so we will use one-hot encoding to encode them. The education level variable, however, is ordinal (meaning there is some order, but the distances between them don't necessarily mean anything), so we will use label encoding for that variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_one_hot = ['class', 'marital_status', 'occupation', 'relationship', 'race', 'native_country']\n",
    "adult_dataset = pd.get_dummies(adult_dataset, columns=columns_to_one_hot, prefix=columns_to_one_hot)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "adult_dataset['education_level'] = label_encoder.fit_transform(adult_dataset['education_level'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adult_dataset.dtypes)\n",
    "adult_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that each feature is in the format a machine can handle and intepret properly, the data is ready for modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: [Heart Disease](http://archive.ics.uci.edu/dataset/45/heart+disease)\n",
    "Heart disease dataset from four databases predicting if a person has heart disease based on various features. 3 of the databases were riddled with missing values, so we will use the Cleveland database. 303 instances, 14 features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and assign column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"age\", \"sex\", \"cp\", \"resting_bp\", \"cholesterol\", \"blood_sugar\", \"resting_ekg\", \"max_hr\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"severity\"]\n",
    "\n",
    "\n",
    "heart_dataset = pd.read_csv('heart_dataset/processed.cleveland.data', header=None, names=column_names) # read the dataset\n",
    "heart_dataset = heart_dataset[~heart_dataset.map(lambda x: str(x).strip()).isin(['?']).any(axis=1)] # remove rows with missing values\n",
    "heart_dataset['ca'] = heart_dataset['ca'].astype(float) # convert to float\n",
    "heart_dataset['thal'] = heart_dataset['thal'].astype(float) # convert to float\n",
    "heart_dataset['severity'] = heart_dataset['severity'].apply(lambda x: 0 if x == 0 else 1) # convert to binary for 2 class classification\n",
    "\n",
    "print(heart_dataset.dtypes)\n",
    "heart_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is already clean and ready for modeling, so we are done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3:\n",
    "Wine dataset; predicting the quality of wine based on various features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and assign column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the qualities of a good red wine might be different from those of a good white wine, I will split the dataset into two and model them separately, as well as model the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_dataset = pd.read_csv('wine_dataset/winequality-red.csv', sep=';') # read the dataset\n",
    "white_wine_dataset = pd.read_csv('wine_dataset/winequality-white.csv', sep=';') # read the dataset\n",
    "red_white_wine_dataset = pd.concat([red_wine_dataset, white_wine_dataset], axis=0) # concatenate the datasets\n",
    "wine_datasets = [red_wine_dataset, white_wine_dataset, red_white_wine_dataset] \n",
    "\n",
    "for i, dataset in enumerate(wine_datasets, start=1):\n",
    "    dataset['quality'] = dataset['quality'].apply(lambda x: 0 if x <= 6 else 1) # convert to binary for 2 class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(red_wine_dataset.dtypes)\n",
    "red_wine_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(red_wine_dataset.dtypes)\n",
    "white_wine_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(red_white_wine_dataset.dtypes)\n",
    "red_white_wine_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is already clean and ready for modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use the following models for each dataset: Support Vector Machine, Random Forest, and Logistic Regression. For each of the models I will:\n",
    "\n",
    "- Preprocess the data\n",
    "    - Scale the data using StandardScaler to standardize the input values for better model performance\n",
    "    - Separate the data into features and target column\n",
    "\n",
    "- Partition the data into training and testing sets\n",
    "    - Use 20/80, 50/50, and 80/20 splits to evaluate model performance under different training/testing ratios\n",
    "\n",
    "- Perform hyperparameter tuning using GridSearchCV\n",
    "    - Tune the hyperparameters for each model to optimize performance\n",
    "\n",
    "- Train the model\n",
    "    - Fit the model on the training data for each partition using the best hyperparameters\n",
    "\n",
    "- Evaluate the model\n",
    "    - Evaluate the model using cross scores to compute the average validation accuracy\n",
    "    - Evaluate the model on the test set to compute the test accuracy\n",
    "    - Generate classification reports to analyze precision, recall, and F1 scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_with_partitions(df, target_column):\n",
    "\n",
    "    # Prepare features and target\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Define partitions (test/train split ratios)\n",
    "    partitions = {\n",
    "        \"20/80\": 0.2,\n",
    "        \"50/50\": 0.5,\n",
    "        \"80/20\": 0.8\n",
    "    }\n",
    "    \n",
    "    results = []  # Store results for analysis\n",
    "    for partition_name, test_size in tqdm(partitions.items(), desc=\"Partitions\"):\n",
    "        print(f\"\\nTraining with {partition_name} partition...\")\n",
    "        \n",
    "        # Split data into training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        # Define hyperparameter grid\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10], \n",
    "            'gamma': ['scale', 0.1],  \n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "\n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        \n",
    "        # Evaluate cross-validation accuracy on training set\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        avg_cv_score = np.mean(cv_scores)\n",
    "        print(f\"Average cross-validation accuracy: {avg_cv_score:.2f}\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Partition\": partition_name,\n",
    "            \"CV Accuracy\": avg_cv_score,\n",
    "            \"Test Accuracy\": test_accuracy\n",
    "        })\n",
    "        \n",
    "        # Visualize confusion matrix\n",
    "        ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n",
    "        plt.title(f\"Confusion Matrix: {partition_name} Partition\")\n",
    "        plt.show()\n",
    "\n",
    "    # Display summarized results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(results_df)\n",
    "    \n",
    "    # Plot training vs. testing accuracies\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(results_df[\"Partition\"], results_df[\"CV Accuracy\"], label=\"Validation Accuracy\", marker='o')\n",
    "    plt.plot(results_df[\"Partition\"], results_df[\"Test Accuracy\"], label=\"Test Accuracy\", marker='o')\n",
    "    plt.xlabel(\"Partition\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"SVM Performance Across Partitions\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_with_partitions(df, target_column):\n",
    "\n",
    "    # Prepare features and target\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Define partitions\n",
    "    partitions = {\n",
    "        \"20/80\": 0.2,\n",
    "        \"50/50\": 0.5,\n",
    "        \"80/20\": 0.8\n",
    "    }\n",
    "    \n",
    "    results = []  # Store results for analysis\n",
    "    for partition_name, test_size in tqdm(partitions.items(), desc=\"Partitions\"):\n",
    "        print(f\"\\nTraining with {partition_name} partition...\")\n",
    "        \n",
    "        # Split data into training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        # Define hyperparameter grid\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],  \n",
    "            'max_depth': [None, 10, 20], \n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "\n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        \n",
    "        # Evaluate cross-validation accuracy on training set\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        avg_cv_score = np.mean(cv_scores)\n",
    "        print(f\"Average cross-validation accuracy: {avg_cv_score:.2f}\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Partition\": partition_name,\n",
    "            \"CV Accuracy\": avg_cv_score,\n",
    "            \"Test Accuracy\": test_accuracy\n",
    "        })\n",
    "        \n",
    "        # Visualize confusion matrix\n",
    "        ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n",
    "        plt.title(f\"Confusion Matrix: {partition_name} Partition\")\n",
    "        plt.show()\n",
    "\n",
    "    # Display summarized results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(results_df)\n",
    "    \n",
    "    # Plot training vs. testing accuracies\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(results_df[\"Partition\"], results_df[\"CV Accuracy\"], label=\"Validation Accuracy\", marker='o')\n",
    "    plt.plot(results_df[\"Partition\"], results_df[\"Test Accuracy\"], label=\"Test Accuracy\", marker='o')\n",
    "    plt.xlabel(\"Partition\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Random Forest Performance Across Partitions\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression_with_partitions(df, target_column):\n",
    "\n",
    "    # Prepare features and target\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Define partitions\n",
    "    partitions = {\n",
    "        \"20/80\": 0.2,\n",
    "        \"50/50\": 0.5,\n",
    "        \"80/20\": 0.8\n",
    "    }\n",
    "    \n",
    "    results = []  # Store results for analysis\n",
    "    for partition_name, test_size in tqdm(partitions.items(), desc=\"Partitions\"):\n",
    "        print(f\"\\nTraining with {partition_name} partition...\")\n",
    "        \n",
    "        # Split data into training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        # Define hyperparameter grid\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],  \n",
    "            'penalty': ['l1', 'l2'],  \n",
    "            'solver': ['liblinear', 'saga'] ,\n",
    "            'fit_intercept': [True, False]\n",
    "        }\n",
    "\n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        \n",
    "        # Evaluate cross-validation accuracy on training set\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        avg_cv_score = np.mean(cv_scores)\n",
    "        print(f\"Average cross-validation accuracy: {avg_cv_score:.2f}\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Partition\": partition_name,\n",
    "            \"CV Accuracy\": avg_cv_score,\n",
    "            \"Test Accuracy\": test_accuracy\n",
    "        })\n",
    "        \n",
    "        # Visualize confusion matrix\n",
    "        ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n",
    "        plt.title(f\"Confusion Matrix: {partition_name} Partition\")\n",
    "        plt.show()\n",
    "\n",
    "    # Display summarized results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(results_df)\n",
    "    \n",
    "    # Plot training vs. testing accuracies\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(results_df[\"Partition\"], results_df[\"CV Accuracy\"], label=\"Validation Accuracy\", marker='o')\n",
    "    plt.plot(results_df[\"Partition\"], results_df[\"Test Accuracy\"], label=\"Test Accuracy\", marker='o')\n",
    "    plt.xlabel(\"Partition\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Logistic Regression Performance Across Partitions\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SVM on all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\"name\": \"Adult Dataset\", \"data\": adult_dataset, \"target\": \"salary\"},\n",
    "    {\"name\": \"Heart Dataset\", \"data\": heart_dataset, \"target\": \"severity\"},\n",
    "    {\"name\": \"Red Wine Dataset\", \"data\": red_wine_dataset, \"target\": \"quality\"},\n",
    "    {\"name\": \"White Wine Dataset\", \"data\": white_wine_dataset, \"target\": \"quality\"},\n",
    "    {\"name\": \"Red and White Wine Dataset\", \"data\": red_white_wine_dataset, \"target\": \"quality\"}\n",
    "]\n",
    "\n",
    "for i, dataset_info in enumerate(tqdm(datasets, desc=\"Datasets\"), start=1):\n",
    "    dataset_name = dataset_info[\"name\"]\n",
    "    dataset = dataset_info[\"data\"]\n",
    "    target_column = dataset_info[\"target\"]\n",
    "    print(f\"\\nTraining on '{dataset_name}' with target column '{target_column}'...\")\n",
    "    train_svm_with_partitions(dataset, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Analysis\n",
    "type here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running random forest on all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\"name\": \"Adult Dataset\", \"data\": adult_dataset, \"target\": \"salary\"},\n",
    "    {\"name\": \"Heart Dataset\", \"data\": heart_dataset, \"target\": \"severity\"},\n",
    "    {\"name\": \"Red Wine Dataset\", \"data\": red_wine_dataset, \"target\": \"quality\"},\n",
    "    {\"name\": \"White Wine Dataset\", \"data\": white_wine_dataset, \"target\": \"quality\"},\n",
    "    {\"name\": \"Red and White Wine Dataset\", \"data\": red_white_wine_dataset, \"target\": \"quality\"}\n",
    "]\n",
    "\n",
    "for i, dataset_info in enumerate(tqdm(datasets, desc=\"Datasets\"), start=1):\n",
    "    dataset_name = dataset_info[\"name\"]\n",
    "    dataset = dataset_info[\"data\"]\n",
    "    target_column = dataset_info[\"target\"]\n",
    "    print(f\"\\nTraining on '{dataset_name}' with target column '{target_column}'...\")\n",
    "    train_random_forest_with_partitions(dataset, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Analysis\n",
    "type here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running logistic regression on all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\"name\": \"Adult Dataset\", \"data\": adult_dataset, \"target\": \"salary\"},\n",
    "    {\"name\": \"Heart Dataset\", \"data\": heart_dataset, \"target\": \"severity\"},\n",
    "    {\"name\": \"Red Wine Dataset\", \"data\": red_wine_dataset, \"target\": \"quality\"},\n",
    "    {\"name\": \"White Wine Dataset\", \"data\": white_wine_dataset, \"target\": \"quality\"},\n",
    "    {\"name\": \"Red and White Wine Dataset\", \"data\": red_white_wine_dataset, \"target\": \"quality\"}\n",
    "]\n",
    "\n",
    "for i, dataset_info in enumerate(tqdm(datasets, desc=\"Datasets\"), start=1):\n",
    "    dataset_name = dataset_info[\"name\"]\n",
    "    dataset = dataset_info[\"data\"]\n",
    "    target_column = dataset_info[\"target\"]\n",
    "    print(f\"\\nTraining on '{dataset_name}' with target column '{target_column}'...\")\n",
    "    train_logistic_regression_with_partitions(dataset, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Analysis\n",
    "type here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs118a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
